{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the results text file to a dictionary\n",
    "def read_results(results_fp):\n",
    "    with open(results_fp, 'r') as f:\n",
    "        data = f.read()\n",
    "    # reconstructing the data as a dictionary\n",
    "    tmp = ast.literal_eval(data)\n",
    "    # removing the get_URLs\n",
    "    control_dict = remove_D_get(tmp)\n",
    "    return(control_dict)\n",
    "\n",
    "# remove the get_URL from the dictionary\n",
    "def remove_D_get(data):\n",
    "    new_dict = copy.deepcopy(data)\n",
    "    for pid in new_dict:\n",
    "        for drug in new_dict[pid]['drugs']:\n",
    "            new_dict[pid]['drugs'][drug].pop('get_URL', None)\n",
    "    return new_dict\n",
    "\n",
    "# reformat the dictionary to be a CSV file with each drug-reaction pair as a row\n",
    "def reformat_to_csv(data):\n",
    "    # open the file to write to\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/results.csv\", \"w\") as myfile:\n",
    "        writer = csv.writer(myfile, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "        \n",
    "        # add header row\n",
    "        header = ['Report_ID', 'Group', 'Drug_name','D_number', 'D_group', 'D_target', 'D_pathway', 'Reaction']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        # make a row for each drug-reaction pair by adding relevant information to a list\n",
    "        for pid in data:\n",
    "            # iterate through each drug\n",
    "            for drug in data[pid]['drugs']:\n",
    "                # iterate through each reaction and write a row for each\n",
    "                for reaction in data[pid]['reactions_MedDRA']:\n",
    "                    row = []\n",
    "                    row.append(pid)\n",
    "                    row.append(data[pid]['group'])\n",
    "                    row.append(drug)\n",
    "                    # if D_number is empty, append \"NA\"\n",
    "                    if not data[pid]['drugs'][drug]['D_number']:\n",
    "                        row.append(\"NA\")\n",
    "                        row.append(\"NA\")\n",
    "                        row.append(\"NA\")\n",
    "                        row.append(\"NA\")\n",
    "                        row.append(reaction)\n",
    "                        writer.writerow(row)\n",
    "                    else :\n",
    "                        row.append(data[pid]['drugs'][drug]['D_number'])\n",
    "                        # if classes row is \"set()\", append \"NA\"\n",
    "                        if str(data[pid]['drugs'][drug]['Classes']) == \"set()\":\n",
    "                            row.append(\"NA\")\n",
    "                        else : \n",
    "                            temp = data[pid]['drugs'][drug]['Classes']\n",
    "                            # convert the set to a list\n",
    "                            temp = list(temp)\n",
    "                            row.append(temp)\n",
    "                        # if target list is empty, append \"NA\"\n",
    "                        if str(data[pid]['drugs'][drug]['Target']) == \"[]\":\n",
    "                            row.append(\"NA\")\n",
    "                        else :\n",
    "                            row.append(data[pid]['drugs'][drug]['Target'])                            \n",
    "                        # if pathway list is empty, append \"NA\"\n",
    "                        if str(data[pid]['drugs'][drug]['Pathway']) == \"[]\":\n",
    "                            row.append(\"NA\")\n",
    "                        else :\n",
    "                            row.append(data[pid]['drugs'][drug]['Pathway'])\n",
    "                        row.append(reaction)\n",
    "                        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_fp = '/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/results_dictionary.txt'\n",
    "#results_dict = read_results(data_fp)\n",
    "#reformat_to_csv(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create contingency table for each drug-reaction pair\n",
    "def drug_contingency():\n",
    "    \n",
    "    '''\n",
    "    [A] = The number of report_IDs (in the given group) containing the drug of interest and containing the adverse event of interest\n",
    "    [B] = The number of report_IDs (in the given group) containing the drug of interest, but not containing the  adverse event of interest\n",
    "    [C] = The number of report_IDs (in the given group) containing not containing the drug of interest, but containing the adverse event of interest\n",
    "    [D] = The number of report_IDs (in the given group) containing neither the drug of interest nor the adverse event of interest\n",
    "    '''\n",
    "    \n",
    "    # Open the input file and create a CSV reader\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/results.csv\", \"r\") as infile:\n",
    "        reader = csv.reader(infile, delimiter=\"$\")\n",
    "        next(reader)  # Skip header\n",
    "\n",
    "        # Create nested defaultdicts to store the data and report counts\n",
    "        data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "        group_report_counts = defaultdict(int)\n",
    "        group_drug_report_counts = defaultdict(lambda: defaultdict(int))\n",
    "        group_reaction_report_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # Iterate through the rows in the input file\n",
    "        for row in reader:\n",
    "            report_id, group, drug_name, d_number, D_group, D_target, D_pathway, reaction = row\n",
    "            # Increment the count for the current combination of group, drug, and reaction\n",
    "            data[group][(drug_name, d_number, D_group, reaction)][\"A\"] += 1\n",
    "            group_report_counts[group] += 1\n",
    "            group_drug_report_counts[group][(drug_name, d_number)] += 1\n",
    "            group_reaction_report_counts[group][reaction] += 1\n",
    "\n",
    "    # Open the output file and create a CSV writer\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_contingency.csv\", \"w\") as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\"$\")\n",
    "        # Write the header row\n",
    "        writer.writerow([\"Group\", \"Drug_name\", \"D_number\", \"D_Group\", \"Reaction\", \"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "        # Iterate through the groups in the data\n",
    "        for group in data:\n",
    "\n",
    "            # Iterate through the drug_name, d_number, and reaction combinations in the group\n",
    "            for (drug_name, d_number, D_group, reaction), counts in data[group].items():\n",
    "                a = counts[\"A\"]  # The number of reports with the drug and reaction\n",
    "                b = group_drug_report_counts[group][(drug_name, d_number)] - a  # The number of reports with the drug but not the reaction\n",
    "                c = group_reaction_report_counts[group][reaction] - a  # The number of reports without the drug but with the reaction\n",
    "                d = group_report_counts[group] - a - b - c  # The number of reports without the drug and reaction\n",
    "\n",
    "                # writer.writerow([group, drug_name, d_number, D_group, reaction, a, b, c, d])\n",
    "\n",
    "                # Write the row if A, B, C, and D are all greater than 3\n",
    "                if a > 3 and b > 3 and c > 3 and d > 3:\n",
    "                    writer.writerow([group, drug_name, d_number, D_group, reaction, a, b, c, d])\n",
    "                #else:\n",
    "                #    writer.writerow([group, drug_name, d_number, D_group, reaction, a, b, c, d])\n",
    "\n",
    "drug_contingency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create contingency table for drug group-reaction pair\n",
    "def dg_contingency():\n",
    "    # Open the input file and create a CSV reader\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/results.csv\", \"r\") as infile:\n",
    "        reader = csv.reader(infile, delimiter=\"$\")\n",
    "        next(reader)  # Skip header\n",
    "\n",
    "        # Create nested defaultdicts to store the data and report counts\n",
    "        data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "        group_report_counts = defaultdict(int)\n",
    "        group_d_group_report_counts = defaultdict(lambda: defaultdict(int))\n",
    "        group_reaction_report_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # Iterate through the rows in the input file\n",
    "        for row in reader:\n",
    "            report_id, group, _, _, d_group_str, _, _, reaction = row\n",
    "\n",
    "            try:\n",
    "                # Convert the string representation of the d_group list to a list, \n",
    "                d_groups = ast.literal_eval(d_group_str)\n",
    "            \n",
    "                for d_group_tuple in d_groups:\n",
    "                    d_group = str(d_group_tuple)\n",
    "                    # Increment the count for the current combination of group, d_group, and reaction\n",
    "                    data[group][(d_group, reaction)][\"A\"] += 1\n",
    "                    group_report_counts[group] += 1\n",
    "                    group_d_group_report_counts[group][d_group] += 1\n",
    "                    group_reaction_report_counts[group][reaction] += 1\n",
    "            except ValueError:\n",
    "                # print(f\"Error parsing d_group string: {d_group_str}\")\n",
    "                continue\n",
    "            \n",
    "    # Open the output file and create a CSV writer\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_contingency.csv\", \"w\") as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\"$\")\n",
    "        # Write the header row\n",
    "        writer.writerow([\"Group\", \"D_group\", \"Reaction\", \"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "        # Iterate through the groups in the data\n",
    "        for group in data:\n",
    "            # Iterate through the d_group and reaction combinations in the group\n",
    "            for (d_group, reaction), counts in data[group].items():\n",
    "                a = counts[\"A\"]  # The number of reports with the d_group and reaction\n",
    "                b = group_d_group_report_counts[group][d_group] - a  # The number of reports with the d_group but not the reaction\n",
    "                c = group_reaction_report_counts[group][reaction] - a  # The number of reports without the d_group but with the reaction\n",
    "                d = group_report_counts[group] - a - b - c  # The number of reports without the d_group and reaction\n",
    "\n",
    "                # writer.writerow([group, d_group, reaction, a, b, c, d])\n",
    "\n",
    "                # Write the row if A, B, C, and D are all greater than 3\n",
    "                if a > 3 and b > 3 and c > 3 and d > 3:\n",
    "                    writer.writerow([group, d_group, reaction, a, b, c, d])\n",
    "                #else:\n",
    "                #    writer.writerow([group, d_group, reaction, \"null\",\"null\" ,\"null\" ,\"null\" ])\n",
    "\n",
    "\n",
    "dg_contingency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create contingency table for each drug pathway-reaction pair\n",
    "def dp_contingency():\n",
    "    # Open the input file and create a CSV reader\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/results.csv\", \"r\") as infile:\n",
    "        reader = csv.reader(infile, delimiter=\"$\")\n",
    "        next(reader)  # Skip header\n",
    "\n",
    "        # Create nested defaultdicts to store the data and report counts\n",
    "        data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "        group_report_counts = defaultdict(int)\n",
    "        group_d_pathway_report_counts = defaultdict(lambda: defaultdict(int))\n",
    "        group_reaction_report_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        # Iterate through the rows in the input file\n",
    "        for row in reader:\n",
    "            report_id, group, _, _, _, _, d_pathway_str, reaction = row\n",
    "\n",
    "            try:\n",
    "                # Convert the string representation of the d_pathway list to a list\n",
    "                d_pathways = ast.literal_eval(d_pathway_str)\n",
    "\n",
    "                for d_pathway in d_pathways:\n",
    "                    # Increment the count for the current combination of group, d_pathway, and reaction\n",
    "                    data[group][(d_pathway, reaction)][\"A\"] += 1\n",
    "                    group_report_counts[group] += 1\n",
    "                    group_d_pathway_report_counts[group][d_pathway] += 1\n",
    "                    group_reaction_report_counts[group][reaction] += 1\n",
    "            except ValueError:\n",
    "                # print(f\"Error parsing d_pathway string: {d_pathway_str}\")\n",
    "                continue\n",
    "\n",
    "    # Open the output file and create a CSV writer\n",
    "    with open(\"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_contingency.csv\", \"w\") as outfile:\n",
    "        writer = csv.writer(outfile, delimiter=\"$\")\n",
    "        # Write the header row\n",
    "        writer.writerow([\"Group\", \"D_pathway\", \"Reaction\", \"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "        # Iterate through the groups in the data\n",
    "        for group in data:\n",
    "            # Iterate through the d_pathway and reaction combinations in the group\n",
    "            for (d_pathway, reaction), counts in data[group].items():\n",
    "                a = counts[\"A\"]  # The number of reports with the d_pathway and reaction\n",
    "                b = group_d_pathway_report_counts[group][d_pathway] - a  # The number of reports with the d_pathway but not the reaction\n",
    "                c = group_reaction_report_counts[group][reaction] - a  # The number of reports without the d_pathway but with the reaction\n",
    "                d = group_report_counts[group] - a - b - c  # The number of reports without the d_pathway and reaction\n",
    "\n",
    "                # writer.writerow([group, d_pathway, reaction, a, b, c, d])\n",
    "\n",
    "                # Write the row if A, B, C, and D are all greater than 3\n",
    "                if a > 3 and b > 3 and c > 3 and d > 3:\n",
    "                    writer.writerow([group, d_pathway, reaction, a, b, c, d])\n",
    "                #else:\n",
    "                #    writer.writerow([group, d_pathway, reaction, \"null\",\"null\" ,\"null\" ,\"null\" ])\n",
    "\n",
    "\n",
    "dp_contingency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform drug disproportionality analysis and write the results to a new file called drug_disproportionality.csv\n",
    "def drug_disproportionality_analysis():    \n",
    "    '''\n",
    "    [A] = The number of report_IDs (in the given group) containing the drug of interest and containing the adverse event of interest\n",
    "    [B] = The number of report_IDs (in the given group) containing the drug of interest, but not containing the  adverse event of interest\n",
    "    [C] = The number of report_IDs (in the given group) not containing the drug of interest, but containing the adverse event of interest\n",
    "    [D] = The number of report_IDs (in the given group) containing neither the drug of interest nor the adverse event of interest\n",
    "    '''\n",
    "    with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_contingency.csv', 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "        with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_disproportionality.csv', 'w') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "            # write header row\n",
    "            writer.writerow(['Group', 'Drug', 'D_number', 'D_group', 'Reaction', 'N_observed', 'PRR'])\n",
    "            # skip the header row in the reader\n",
    "            next(reader)\n",
    "            # iterate through each row in contingency.csv\n",
    "            for row in reader:\n",
    "                # PRR = (A / (A+B)) / (C/ (C+D))\n",
    "                A, B, C, D = int(row[5]), int(row[6]), int(row[7]), int(row[8])\n",
    "\n",
    "                # calculate the PRR if A, B, C, and D are all greater than or equal to 3\n",
    "                if A >= 3 and B >= 3 and C >= 3 and D >= 3:\n",
    "                    PRR = (A/(A+B)) / (C/(C+D))\n",
    "                    # write the row to the file\n",
    "                    writer.writerow([row[0], row[1], row[2], row[3], row[4], A, PRR])\n",
    "                # else, write the row to the file with a PRR = nan\n",
    "                #else:\n",
    "                #    writer.writerow([row[0], row[1], row[2], row[3], row[4], A, 'nan'])\n",
    "\n",
    "# perform dg disproportionality analysis and write the results to a new file called dg_disproportionality.csv\n",
    "def dg_disproportionality_analysis():\n",
    "    with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_contingency.csv', 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "        with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_disproportionality.csv', 'w') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "            # write header row\n",
    "            writer.writerow(['Group', 'KEGG_Dgroup', 'Reaction', 'N_observed', 'PRR'])\n",
    "            # skip the header row in the reader\n",
    "            next(reader)\n",
    "            # iterate through each row in contingency.csv\n",
    "            for row in reader:\n",
    "                \n",
    "                A, B, C, D = int(row[3]), int(row[4]), int(row[5]), int(row[6])\n",
    "                \n",
    "                # calculate the PRR if A, B, C, and D are all greater than or equal to 3\n",
    "                if A >= 3 and B >= 3 and C >= 3 and D >= 3:\n",
    "                    PRR = (A/(A+B)) / (C/(C+D))\n",
    "                    # write the row to the file\n",
    "                    writer.writerow([row[0], row[1], row[2], A, PRR])\n",
    "                # else, write the row to the file with PRR = nan\n",
    "                #else:\n",
    "                #    writer.writerow([row[0], row[1], row[2], A, 'nan'])\n",
    "\n",
    "\n",
    "drug_disproportionality_analysis()\n",
    "dg_disproportionality_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform dp disproportionality analysis and write the results to a new file called dp_disproportionality.csv\n",
    "def dp_disproportionality_analysis():\n",
    "    with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_contingency.csv', 'r') as file:\n",
    "        reader = csv.reader(file, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "        with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_disproportionality.csv', 'w') as outfile:\n",
    "            writer = csv.writer(outfile, delimiter='$', quoting=csv.QUOTE_NONE)\n",
    "            # write header row\n",
    "            writer.writerow(['Group', 'D_pathway', 'Reaction', 'N_observed', 'PRR'])\n",
    "            # skip the header row in the reader\n",
    "            next(reader)\n",
    "            # iterate through each row in contingency.csv\n",
    "            for row in reader:\n",
    "\n",
    "                A, B, C, D = int(row[3]), int(row[4]), int(row[5]), int(row[6])\n",
    "\n",
    "                # calculate the PRR if A, B, C, and D are all greater than or equal to 3\n",
    "                if A >= 3 and B >= 3 and C >= 3 and D >= 3:\n",
    "                    PRR = (A/(A+B)) / (C/(C+D))\n",
    "                    # write the row to the file\n",
    "                    writer.writerow([row[0], row[1], row[2], A, PRR])\n",
    "                # else, write the row to the file with a PRR = nan\n",
    "                #else:\n",
    "                #    writer.writerow([row[0], row[1], row[2], A, 'nan'])\n",
    "\n",
    "dp_disproportionality_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a chi-squared (with Yates' correction) and p-value column to the drug_disproportionality.csv file\n",
    "def drug_chi_squared_yates(a, b, c, d):\n",
    "    row_total1 = a + b\n",
    "    row_total2 = c + d\n",
    "    col_total1 = a + c\n",
    "    col_total2 = b + d\n",
    "    total_obs = a + b + c + d\n",
    "\n",
    "    expected_a = (row_total1 * col_total1) / total_obs\n",
    "    expected_b = (row_total1 * col_total2) / total_obs\n",
    "    expected_c = (row_total2 * col_total1) / total_obs\n",
    "    expected_d = (row_total2 * col_total2) / total_obs\n",
    "\n",
    "    # apply chi-squared with Yates' correction\n",
    "    chi_squared = (np.abs(a - expected_a) - 0.5) ** 2 / expected_a + \\\n",
    "                  (np.abs(b - expected_b) - 0.5) ** 2 / expected_b + \\\n",
    "                  (np.abs(c - expected_c) - 0.5) ** 2 / expected_c + \\\n",
    "                  (np.abs(d - expected_d) - 0.5) ** 2 / expected_d\n",
    "    \n",
    "    deg_freedom = 1  # degrees of freedom\n",
    "    p_value = chi2.sf(chi_squared, deg_freedom)  # survival function (1 - CDF)\n",
    "                  \n",
    "    return chi_squared, p_value\n",
    "\n",
    "\n",
    "# Read the CSV files, separator = $\n",
    "contingency_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_contingency.csv', sep='$')\n",
    "disproportionality_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_disproportionality.csv', sep='$')\n",
    "\n",
    "# Calculate chi-squared and p-values for rows with PRR != nan\n",
    "chi_squared_values = []\n",
    "p_values = []\n",
    "for _, row in contingency_df.iterrows():\n",
    "    #if np.isnan(row['PRR']):\n",
    "    #    chi_squared_values.append('nan')\n",
    "    #    p_values.append('nan')\n",
    "    #    continue\n",
    "    chi_squared, p_value = drug_chi_squared_yates(row['A'], row['B'], row['C'], row['D'])\n",
    "    chi_squared_values.append(chi_squared)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Add chi-squared and p-values to the disproportionality_df\n",
    "disproportionality_df['Chi_squared'] = chi_squared_values\n",
    "disproportionality_df['P_value'] = p_values\n",
    "\n",
    "# drop rows with PRR = \"nan\"\n",
    "# disproportionality_df = disproportionality_df[disproportionality_df['PRR'] != 'nan']\n",
    "\n",
    "# Save the updated disproportionality_df to a csv file, replacing the old one\n",
    "disproportionality_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_disproportionality.csv', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a chi-squared (with Yates' correction) column to the dg_disproportionality.csv file\n",
    "def dg_chi_squared_yates(a, b, c, d):\n",
    "    row_total1 = a + b\n",
    "    row_total2 = c + d\n",
    "    col_total1 = a + c\n",
    "    col_total2 = b + d\n",
    "    total_obs = a + b + c + d\n",
    "\n",
    "    expected_a = (row_total1 * col_total1) / total_obs\n",
    "    expected_b = (row_total1 * col_total2) / total_obs\n",
    "    expected_c = (row_total2 * col_total1) / total_obs\n",
    "    expected_d = (row_total2 * col_total2) / total_obs\n",
    "\n",
    "    # apply chi-squared with Yates' correction\n",
    "    chi_squared = (np.abs(a - expected_a) - 0.5) ** 2 / expected_a + \\\n",
    "                  (np.abs(b - expected_b) - 0.5) ** 2 / expected_b + \\\n",
    "                  (np.abs(c - expected_c) - 0.5) ** 2 / expected_c + \\\n",
    "                  (np.abs(d - expected_d) - 0.5) ** 2 / expected_d\n",
    "\n",
    "    deg_freedom = 1  # degrees of freedom\n",
    "    p_value = chi2.sf(chi_squared, deg_freedom)  # survival function (1 - CDF)              \n",
    "    \n",
    "    return chi_squared, p_value\n",
    "\n",
    "# Read the CSV files, separator = $\n",
    "contingency_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_contingency.csv', sep='$')\n",
    "disproportionality_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_disproportionality.csv', sep='$')\n",
    "\n",
    "# Calculate chi-squared and p-values for rows with PRR != nan\n",
    "chi_squared_values = []\n",
    "p_values = []\n",
    "for _, row in contingency_df.iterrows():\n",
    "    #if np.isnan(row['PRR']):\n",
    "    #    chi_squared_values.append('nan')\n",
    "    #    p_values.append('nan')\n",
    "    #    continue\n",
    "    chi_squared, p_value = dg_chi_squared_yates(row['A'], row['B'], row['C'], row['D'])\n",
    "    chi_squared_values.append(chi_squared)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Add chi-squared and p-values to the disproportionality_df\n",
    "disproportionality_df['Chi_squared'] = chi_squared_values\n",
    "disproportionality_df['P_value'] = p_values\n",
    "\n",
    "# drop rows with PRR = \"nan\"\n",
    "# disproportionality_df = disproportionality_df[disproportionality_df['PRR'] != 'nan']\n",
    "\n",
    "# Save the updated disproportionality_df, replacing the old dg_disproportionality.csv file\n",
    "disproportionality_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_disproportionality.csv', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a chi-squared (with Yates' correction) column to the dp_disproportionality.csv file\n",
    "def dp_chi_squared_yates(a, b, c, d):\n",
    "    row_total1 = a + b\n",
    "    row_total2 = c + d\n",
    "    col_total1 = a + c\n",
    "    col_total2 = b + d\n",
    "    total_obs = a + b + c + d\n",
    "\n",
    "    expected_a = (row_total1 * col_total1) / total_obs\n",
    "    expected_b = (row_total1 * col_total2) / total_obs\n",
    "    expected_c = (row_total2 * col_total1) / total_obs\n",
    "    expected_d = (row_total2 * col_total2) / total_obs\n",
    "\n",
    "    # apply chi-squared with Yates' correction\n",
    "    chi_squared = (np.abs(a - expected_a) - 0.5) ** 2 / expected_a + \\\n",
    "                  (np.abs(b - expected_b) - 0.5) ** 2 / expected_b + \\\n",
    "                  (np.abs(c - expected_c) - 0.5) ** 2 / expected_c + \\\n",
    "                  (np.abs(d - expected_d) - 0.5) ** 2 / expected_d\n",
    "\n",
    "    deg_freedom = 1  # degrees of freedom\n",
    "    p_value = chi2.sf(chi_squared, deg_freedom)  # survival function (1 - CDF)              \n",
    "    \n",
    "    return chi_squared, p_value\n",
    "\n",
    "# Read the CSV files, separator = $\n",
    "contingency_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_contingency.csv', sep='$')\n",
    "disproportionality_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_disproportionality.csv', sep='$')\n",
    "\n",
    "# Calculate chi-squared and p-values for rows with PRR != nan\n",
    "chi_squared_values = []\n",
    "p_values = []\n",
    "for _, row in contingency_df.iterrows():\n",
    "    #if np.isnan(row['PRR']):\n",
    "    #    chi_squared_values.append('nan')\n",
    "    #    p_values.append('nan')\n",
    "    #    continue\n",
    "    chi_squared, p_value = dp_chi_squared_yates(row['A'], row['B'], row['C'], row['D'])\n",
    "    chi_squared_values.append(chi_squared)\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# Add chi-squared and p-values to the disproportionality_df\n",
    "disproportionality_df['Chi_squared'] = chi_squared_values\n",
    "disproportionality_df['P_value'] = p_values\n",
    "\n",
    "# drop rows with PRR = \"nan\"\n",
    "# disproportionality_df = disproportionality_df[disproportionality_df['PRR'] != 'nan']\n",
    "\n",
    "# Save the updated disproportionality_df, replacing the old dp_disproportionality.csv file\n",
    "disproportionality_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_disproportionality.csv', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the PRRs of the two groups in drug_disproportionality and write the results to a new file called drug_comparison.csv\n",
    "def compare_drug_PRRs():\n",
    "    # read drug_disproportionality.csv into a pandas dataframe\n",
    "    disp_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_disproportionality.csv', delimiter='$')\n",
    "    \n",
    "    # create a new dataframe with only the rows from group 0 and remove the group column\n",
    "    group_0 = disp_df.loc[disp_df['Group'] == 0].drop('Group', axis=1)\n",
    "    # create a new dataframe with only the rows from group 1 and remove the group column\n",
    "    group_1 = disp_df.loc[disp_df['Group'] == 1].drop('Group', axis=1)\n",
    "    \n",
    "    # sort the rows in each dataframe by drug name, D_number, D_group, and reaction\n",
    "    group_0 = group_0.sort_values(by=['Drug', 'D_number', 'D_group', 'Reaction'])\n",
    "    group_1 = group_1.sort_values(by=['Drug', 'D_number', 'D_group', 'Reaction'])\n",
    "\n",
    "\n",
    "    # merge the two dataframes on drug name and reaction for each drug reaction pair in group 1\n",
    "    merged_df = pd.merge(group_0, group_1, on=['Drug', 'Reaction', 'D_number'], how='inner')\n",
    "\n",
    "    # rename the P_value_x column to P_value_0 and the P_value_y column to P_value_1\n",
    "    merged_df = merged_df.rename(columns={'P_value_x': 'P_value_0', 'P_value_y': 'P_value_1'})\n",
    "    \n",
    "    # rename the N_observed_y column to N_observed_hw and the N_observed_x column to N_observed_control\n",
    "    merged_df = merged_df.rename(columns={'N_observed_y': 'N_observed_hw', 'N_observed_x': 'N_observed_control'})\n",
    "\n",
    "    # add a column for the quotient of PRRs: PRRR = PRR_y / PRR_x\n",
    "    merged_df['PRRR'] = merged_df['PRR_y'] / merged_df['PRR_x']\n",
    "\n",
    "    # rename the PRR_x column to PRR_0 and the PRR_y column to PRR_1\n",
    "    merged_df = merged_df.rename(columns={'PRR_x': 'PRR_0', 'PRR_y': 'PRR_1'})\n",
    "    \n",
    "    # sort the dataframe by PRRR\n",
    "    merged_df = merged_df.sort_values(by=['PRRR'], ascending=False)\n",
    "\n",
    "    # rename the Chi_squared_x column to Chi_squared_0 and the Chi_squared_y column to Chi_squared_1\n",
    "    merged_df = merged_df.rename(columns={'Chi_squared_x': 'Chi_squared_0', 'Chi_squared_y': 'Chi_squared_1'})\n",
    "\n",
    "\n",
    "    # round PRR_0, PRR_1, PRRR, Chi_squared_0, and Chi_squared_1, P_value_0, and P_value_1\n",
    "    merged_df['PRR_0'] = merged_df['PRR_0'].round(3)\n",
    "    merged_df['PRR_1'] = merged_df['PRR_1'].round(3)\n",
    "    merged_df['PRRR'] = merged_df['PRRR'].round(3)\n",
    "    merged_df['Chi_squared_0'] = merged_df['Chi_squared_0'].round(3)\n",
    "    merged_df['Chi_squared_1'] = merged_df['Chi_squared_1'].round(3)\n",
    "    #merged_df['P_value_0'] = merged_df['P_value_0'].round(5)\n",
    "    #merged_df['P_value_1'] = merged_df['P_value_1'].round(5)\n",
    "\n",
    "\n",
    "    # drop the column D_group_x\n",
    "    merged_df = merged_df.drop('D_group_x', axis=1)\n",
    "    # rename the D_group_y column to D_group\n",
    "    merged_df = merged_df.rename(columns={'D_group_y': 'D_group'})\n",
    "\n",
    "    merged_df = merged_df[['D_number', 'D_group', 'Drug', 'Reaction', 'N_observed_control', 'N_observed_hw', 'Chi_squared_0', 'Chi_squared_1', 'P_value_0', 'P_value_1', 'PRR_0', 'PRR_1', 'PRRR']]\n",
    "\n",
    "\n",
    "    # write the merged dataframe to a new file called comparison.csv\n",
    "    merged_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison.csv', sep='$', index=False)\n",
    "\n",
    "compare_drug_PRRs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the PRRs of the two groups in dg_disproportionality and write the results to a new file called dg_comparison.csv\n",
    "def compare_dg_PRRs():\n",
    "    # read dg_disproportionality.csv into a pandas dataframe\n",
    "    dg_disp_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_disproportionality.csv', delimiter='$')\n",
    "    \n",
    "    \n",
    "    # create a new dataframe with only the rows from group 0 and remove the group column\n",
    "    group_0 = dg_disp_df.loc[dg_disp_df['Group'] == 0].drop('Group', axis=1)\n",
    "    # create a new dataframe with only the rows from group 1 and remove the group column\n",
    "    group_1 = dg_disp_df.loc[dg_disp_df['Group'] == 1].drop('Group', axis=1)\n",
    "\n",
    "    # sort the rows in each dataframe by drug group and reaction\n",
    "    group_0 = group_0.sort_values(by=['KEGG_Dgroup', 'Reaction'])\n",
    "    group_1 = group_1.sort_values(by=['KEGG_Dgroup', 'Reaction'])\n",
    "\n",
    "    # merge the two dataframes on drug group and reaction for each drug reaction pair in group 1\n",
    "    merged_df = pd.merge(group_0, group_1, on=['KEGG_Dgroup', 'Reaction'], how='inner')\n",
    "\n",
    "    # rename the P_value_x column to P_value_0 and the P_value_y column to P_value_1\n",
    "    merged_df = merged_df.rename(columns={'P_value_x': 'P_value_0', 'P_value_y': 'P_value_1'})\n",
    "    # rename the N_observed_y column to N_observed_hw and the N_observed_x column to N_observed_control\n",
    "    merged_df = merged_df.rename(columns={'N_observed_y': 'N_observed_hw', 'N_observed_x': 'N_observed_control'})\n",
    "\n",
    "    # add a column for the quotient of PRRs: PRRR = PRR_y / PRR_x\n",
    "    merged_df['PRRR'] = merged_df['PRR_y'] / merged_df['PRR_x']\n",
    "\n",
    "    # rename the PRR_x column to PRR_0 and the PRR_y column to PRR_1\n",
    "    merged_df = merged_df.rename(columns={'PRR_x': 'PRR_0', 'PRR_y': 'PRR_1'})\n",
    "    # rename the Chi_squared_x column to Chi_squared_0 and the Chi_squared_y column to Chi_squared_1\n",
    "    merged_df = merged_df.rename(columns={'Chi_squared_x': 'Chi_squared_0', 'Chi_squared_y': 'Chi_squared_1'})\n",
    "    \n",
    "    # round PRR_0, PRR_1, PRRR, Chi_squared_0, Chi_squared_1, P_value_0, and P_value_1\n",
    "    merged_df['PRR_0'] = merged_df['PRR_0'].round(3)\n",
    "    merged_df['PRR_1'] = merged_df['PRR_1'].round(3)\n",
    "    merged_df['PRRR'] = merged_df['PRRR'].round(3)\n",
    "    merged_df['Chi_squared_0'] = merged_df['Chi_squared_0'].round(3)\n",
    "    merged_df['Chi_squared_1'] = merged_df['Chi_squared_1'].round(3)\n",
    "    #merged_df['P_value_0'] = merged_df['P_value_0'].round(5)\n",
    "    #merged_df['P_value_1'] = merged_df['P_value_1'].round(5)\n",
    "    \n",
    "    # sort the dataframe by PRRR\n",
    "    merged_df = merged_df.sort_values(by=['PRRR'], ascending=False)\n",
    "\n",
    "    # reorder the columns\n",
    "    merged_df = merged_df[['KEGG_Dgroup', 'Reaction', 'N_observed_control', 'N_observed_hw', 'Chi_squared_0', 'Chi_squared_1', 'P_value_0', 'P_value_1', 'PRR_0', 'PRR_1', 'PRRR']]\n",
    "\n",
    "    # write the merged dataframe to a new file called dg_comparison.csv\n",
    "    merged_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison.csv', sep='$', index=False)\n",
    "\n",
    "compare_dg_PRRs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the PRRs of the two groups in dp_disproportionality and write the results to a new file called dp_comparison.csv\n",
    "def compare_dp_PRRs():\n",
    "    # read dg_disproportionality.csv into a pandas dataframe\n",
    "    dp_disp_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_disproportionality.csv', delimiter='$')\n",
    "\n",
    "    # create a new dataframe with only the rows from group 0 and remove the group column\n",
    "    group_0 = dp_disp_df.loc[dp_disp_df['Group'] == 0].drop('Group', axis=1)\n",
    "    # create a new dataframe with only the rows from group 1 and remove the group column\n",
    "    group_1 = dp_disp_df.loc[dp_disp_df['Group'] == 1].drop('Group', axis=1)\n",
    "\n",
    "    # sort the rows in each dataframe by drug pathway and reaction\n",
    "    group_0 = group_0.sort_values(by=['D_pathway', 'Reaction'])\n",
    "    group_1 = group_1.sort_values(by=['D_pathway', 'Reaction'])\n",
    "\n",
    "    # merge the two dataframes on drug pathway and reaction for each pair in group 1\n",
    "    merged_df = pd.merge(group_0, group_1, on=['D_pathway', 'Reaction'], how='inner')\n",
    "\n",
    "    # rename the P_value_x column to P_value_0 and the P_value_y column to P_value_1\n",
    "    merged_df = merged_df.rename(columns={'P_value_x': 'P_value_0', 'P_value_y': 'P_value_1'})\n",
    "    # rename the N_observed_y column to N_observed_hw and the N_observed_x column to N_observed_control\n",
    "    merged_df = merged_df.rename(columns={'N_observed_y': 'N_observed_hw', 'N_observed_x': 'N_observed_control'})\n",
    "\n",
    "    # add a column for the quotient of PRRs: PRRR = PRR_y / PRR_x\n",
    "    merged_df['PRRR'] = merged_df['PRR_y'] / merged_df['PRR_x']\n",
    "\n",
    "    # rename the PRR_x column to PRR_0 and the PRR_y column to PRR_1\n",
    "    merged_df = merged_df.rename(columns={'PRR_x': 'PRR_0', 'PRR_y': 'PRR_1'})\n",
    "    # rename the Chi_squared_x column to Chi_squared_0 and the Chi_squared_y column to Chi_squared_1\n",
    "    merged_df = merged_df.rename(columns={'Chi_squared_x': 'Chi_squared_0', 'Chi_squared_y': 'Chi_squared_1'})\n",
    "\n",
    "    # round PRR_0, PRR_1, PRRR, Chi_squared_0, Chi_squared_1, P_value_0, and P_value_1\n",
    "    merged_df['PRR_0'] = merged_df['PRR_0'].round(3)\n",
    "    merged_df['PRR_1'] = merged_df['PRR_1'].round(3)\n",
    "    merged_df['PRRR'] = merged_df['PRRR'].round(3)\n",
    "    merged_df['Chi_squared_0'] = merged_df['Chi_squared_0'].round(3)\n",
    "    merged_df['Chi_squared_1'] = merged_df['Chi_squared_1'].round(3)\n",
    "    #merged_df['P_value_0'] = merged_df['P_value_0'].round(5)\n",
    "    #merged_df['P_value_1'] = merged_df['P_value_1'].round(5)\n",
    "\n",
    "    # sort the dataframe by PRRR\n",
    "    merged_df = merged_df.sort_values(by=['PRRR'], ascending=False)\n",
    "\n",
    "    # reorder the columns\n",
    "    merged_df = merged_df[['D_pathway', 'Reaction', 'N_observed_control', 'N_observed_hw', 'Chi_squared_0', 'Chi_squared_1', 'P_value_0', 'P_value_1', 'PRR_0', 'PRR_1', 'PRRR']]\n",
    "\n",
    "    # write the merged dataframe to a new file called dp_comparison.csv\n",
    "    merged_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison.csv', sep='$', index=False)\n",
    "\n",
    "compare_dp_PRRs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_final_comparisons():\n",
    "    # read drug_comparison.csv into a pandas dataframe\n",
    "    drug_comparison_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison.csv', delimiter='$')\n",
    "    # read dg_comparison.csv into a pandas dataframe\n",
    "    dg_comparison_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison.csv', delimiter='$')\n",
    "    # read dp_comparison.csv into a pandas dataframe\n",
    "    dp_comparison_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison.csv', delimiter='$')\n",
    "\n",
    "    # drop rows where PRR_1 is less than 2\n",
    "    drug_comparison_df = drug_comparison_df.loc[drug_comparison_df['PRR_1'] >= 2]\n",
    "    dg_comparison_df = dg_comparison_df.loc[dg_comparison_df['PRR_1'] >= 2]\n",
    "    dp_comparison_df = dp_comparison_df.loc[dp_comparison_df['PRR_1'] >= 2]\n",
    "\n",
    "    # drop rows where PRRR is less than 2\n",
    "    drug_comparison_df = drug_comparison_df.loc[drug_comparison_df['PRRR'] >= 2]\n",
    "    dg_comparison_df = dg_comparison_df.loc[dg_comparison_df['PRRR'] >= 2]\n",
    "    dp_comparison_df = dp_comparison_df.loc[dp_comparison_df['PRRR'] >= 2]\n",
    "\n",
    "    # drop rows where Chi_squared_1 is less than 4\n",
    "    drug_comparison_df = drug_comparison_df.loc[drug_comparison_df['Chi_squared_1'] >= 4]\n",
    "    dg_comparison_df = dg_comparison_df.loc[dg_comparison_df['Chi_squared_1'] >= 4]\n",
    "    dp_comparison_df = dp_comparison_df.loc[dp_comparison_df['Chi_squared_1'] >= 4]\n",
    "\n",
    "    # replace all commas in all columns with semicolons\n",
    "    drug_comparison_df = drug_comparison_df.replace(',', ';', regex=True)\n",
    "    dg_comparison_df = dg_comparison_df.replace(',', ';', regex=True)\n",
    "    dp_comparison_df = dp_comparison_df.replace(',', ';', regex=True)\n",
    "\n",
    "    # drop the columns N_observed_control\n",
    "    drug_comparison_df = drug_comparison_df.drop(columns=['N_observed_control'])\n",
    "    dg_comparison_df = dg_comparison_df.drop(columns=['N_observed_control'])\n",
    "    dp_comparison_df = dp_comparison_df.drop(columns=['N_observed_control'])\n",
    "    \n",
    "    # write the dataframes to new files\n",
    "    drug_comparison_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison_formatted.csv', sep='$', index=False)\n",
    "    dg_comparison_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_formatted.csv', sep='$', index=False)\n",
    "    dp_comparison_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison_formatted.csv', sep='$', index=False)\n",
    "\n",
    "create_final_comparisons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows\n",
      "Processed 100 rows\n",
      "Processed 200 rows\n",
      "Processed 300 rows\n",
      "Processed 400 rows\n",
      "Processed 500 rows\n",
      "Processed 600 rows\n",
      "Processed 700 rows\n",
      "Processed 800 rows\n",
      "Processed 900 rows\n",
      "Processed 1000 rows\n",
      "Processed 1100 rows\n",
      "Processed 1200 rows\n",
      "Processed 1300 rows\n",
      "Processed 1400 rows\n",
      "Processed 1500 rows\n",
      "Processed 1600 rows\n",
      "Processed 1700 rows\n",
      "Processed 1800 rows\n",
      "Processed 1900 rows\n",
      "Processed 2000 rows\n",
      "Processed 2100 rows\n",
      "Processed 2200 rows\n",
      "Processed 2300 rows\n"
     ]
    }
   ],
   "source": [
    "# Function to get the DG_name from KEGG API\n",
    "def get_dg_name(dg_id):\n",
    "    url = f\"https://rest.kegg.jp/get/dg:{dg_id}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        for line in response.text.split('\\n'):\n",
    "            if line.startswith(\"NAME\"):\n",
    "                return line.split(\"NAME\")[1].strip()\n",
    "    return \"\"\n",
    "\n",
    "def add_names():\n",
    "    # Input and output file names\n",
    "    input_file = \"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_formatted.csv\"\n",
    "    output_file = \"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_final.csv\"\n",
    "\n",
    "    # Dictionary to store DGroup-DG_name pairs\n",
    "    dg_name_dict = {}\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        csv_reader = csv.reader(infile, delimiter='$')\n",
    "        csv_writer = csv.writer(outfile, delimiter='$')\n",
    "        \n",
    "        # Add the new column header (assuming there's a header row)\n",
    "        header = next(csv_reader)\n",
    "        header.append(\"DG_name\")\n",
    "        csv_writer.writerow(header)\n",
    "        \n",
    "        rowcount = 0\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            \n",
    "            if rowcount % 100 == 0:\n",
    "                print(f\"Processed {rowcount} rows\")\n",
    "            rowcount += 1\n",
    "\n",
    "            dg_id = row[0].split(\";\")[0].replace(\"(\", \"\").replace(\"'\", \"\")\n",
    "            \n",
    "            if dg_id not in dg_name_dict:\n",
    "                dg_name = get_dg_name(dg_id)\n",
    "                # print(f\"DG_name for {dg_id} is {dg_name}\")\n",
    "                dg_name_dict[dg_id] = dg_name\n",
    "                # replace commas with semicolons\n",
    "                dg_name = dg_name.replace(\",\", \";\")\n",
    "            else:\n",
    "                dg_name = dg_name_dict[dg_id]\n",
    "                # print(\"Found in cache\")\n",
    "            \n",
    "            row.append(dg_name)\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "add_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dg_comparison_final.csv into a dataframe\n",
    "dg_comparison_final_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_final.csv', sep='$', header=0)\n",
    "# columns: KEGG_Dgroup$Reaction$N_observed_hw$Chi_squared_0$Chi_squared_1$P_value_0$P_value_1$PRR_0$PRR_1$PRRR$DG_name\n",
    "# reorder columns: KEGG_Dgroup,DG_name,Reaction,N_observed_hw,Chi_squared_0,Chi_squared_1,P_value_0,P_value_1,PRR_0,PRR_1,PRRR\n",
    "dg_comparison_final_df = dg_comparison_final_df[['KEGG_Dgroup', 'DG_name', 'Reaction', 'N_observed_hw', 'Chi_squared_0', 'Chi_squared_1', 'P_value_0', 'P_value_1', 'PRR_0', 'PRR_1', 'PRRR']]\n",
    "# write the dataframe to a csv file, sep = '$'\n",
    "dg_comparison_final_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_final.csv', sep='$', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows\n",
      "Processed 100 rows\n",
      "Processed 200 rows\n",
      "Processed 300 rows\n",
      "Processed 400 rows\n",
      "Processed 500 rows\n",
      "Processed 600 rows\n",
      "Processed 700 rows\n",
      "Processed 800 rows\n"
     ]
    }
   ],
   "source": [
    "def get_pathway_name(pathway_id):\n",
    "    url = f\"https://rest.kegg.jp/get/pathway:{pathway_id}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        for line in response.text.split('\\n'):\n",
    "            if line.startswith(\"NAME\"):\n",
    "                pathway_name = line.split(\"NAME\")[1].strip()\n",
    "                return pathway_name\n",
    "    return \"\"\n",
    "\n",
    "def add_pw_names():\n",
    "\n",
    "    # Input and output file names\n",
    "    input_file = \"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison_formatted.csv\"\n",
    "    output_file = \"/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison_final.csv\"\n",
    "\n",
    "    # Dictionary to store D_pathway-pathway_name pairs\n",
    "    pathway_name_dict = {}\n",
    "\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        csv_reader = csv.reader(infile, delimiter='$')\n",
    "        csv_writer = csv.writer(outfile, delimiter='$')\n",
    "        \n",
    "        # Add the new column header (assuming there's a header row)\n",
    "        header = next(csv_reader)\n",
    "        header.append(\"pathway_name\")\n",
    "        csv_writer.writerow(header)\n",
    "        \n",
    "        rowcount = 0\n",
    "        for row in csv_reader:\n",
    "            if rowcount % 100 == 0:\n",
    "                print(f\"Processed {rowcount} rows\")\n",
    "            rowcount += 1\n",
    "            \n",
    "            pathway_id = row[0]\n",
    "            \n",
    "            if pathway_id not in pathway_name_dict:\n",
    "                pathway_name = get_pathway_name(pathway_id)\n",
    "                pathway_name_dict[pathway_id] = pathway_name\n",
    "                # replace commas with semicolons\n",
    "                pathway_name = pathway_name.replace(\",\", \";\")\n",
    "            else:\n",
    "                pathway_name = pathway_name_dict[pathway_id]\n",
    "                # print(\"Found in cache\")\n",
    "            \n",
    "            row.append(pathway_name)\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "add_pw_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dp_comparison_final_with_names.csv into a dataframe\n",
    "dp_comparison_final_with_names_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison_final.csv', sep='$', header=0)\n",
    "# columns: D_pathway,Reaction,Chi_squared_0,Chi_squared_1,P_value_0,P_value_1,PRR_0,PRR_1,PRRR,pathway_name\n",
    "# reorder columns: D_pathway,pathway_name,Reaction,Chi_squared_0,Chi_squared_1,P_value_0,P_value_1,PRR_0,PRR_1,PRRR\n",
    "dp_comparison_final_with_names_df = dp_comparison_final_with_names_df[['D_pathway', 'pathway_name', 'Reaction', 'Chi_squared_0', 'Chi_squared_1', 'P_value_0', 'P_value_1', 'PRR_0', 'PRR_1', 'PRRR']]\n",
    "# write the dataframe to a csv file, sep = '$'\n",
    "dp_comparison_final_with_names_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dp_comparison_final.csv', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dg_comparison_final.csv into a dataframe\n",
    "dg_comparison_final_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_final.csv', sep='$', header=0)\n",
    "\n",
    "dg_comparison_final_df['DG_level'] = dg_comparison_final_df['KEGG_Dgroup'].apply(lambda x: x.split(';')[1].strip())\n",
    "dg_comparison_final_df['DG_level'] = dg_comparison_final_df['DG_level'].apply(lambda x: x[:-1] if x.endswith(')') else x)\n",
    "\n",
    "dg_comparison_final_df['KEGG_Dgroup'] = dg_comparison_final_df['KEGG_Dgroup'].apply(lambda x: x.split(';')[0].strip(\"'()\"))\n",
    "\n",
    "dg_comparison_final_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/dg_comparison_final_1.csv', sep='$', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rk/6f1nd8k578nbxhsb86z46zch0000gp/T/ipykernel_54728/2337961431.py:5: FutureWarning:\n",
      "\n",
      "The default value of regex will change from True to False in a future version.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "drug_comparison_final_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison_formatted.csv', sep='$', header=0)\n",
    "\n",
    "# replace all instances of the string \");\" with the string \"),\" in the column 'D_group'\n",
    "drug_comparison_final_df['D_group'] = drug_comparison_final_df['D_group'].str.replace(r\"\\);\", \"),\")\n",
    "drug_comparison_final_df['D_group'] = drug_comparison_final_df['D_group'].str.replace(\";\", \",\")\n",
    "\n",
    "drug_comparison_final_df_copy = drug_comparison_final_df.copy()\n",
    "\n",
    "# drop columns 'D_group'$Chi_squared_0$Chi_squared_1$P_value_0$P_value_1$PRR_0$PRR_1\n",
    "drug_comparison_final_df_copy = drug_comparison_final_df_copy.drop(columns=['D_group', 'Chi_squared_0', 'Chi_squared_1', 'P_value_0', 'P_value_1', 'PRR_0', 'PRR_1'])\n",
    "drug_comparison_final_df_copy.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison_final_0.csv', sep='$', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/brite_chem.json') as f:\n",
    "    brite_chem = json.load(f)\n",
    "with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/brite.json') as f:\n",
    "    brite = json.load(f)\n",
    "with open('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/brite_class.json') as f:\n",
    "    brite_class = json.load(f)\n",
    "\n",
    "\n",
    "brite_dict_list = [brite_chem, brite, brite_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  D_number         Drug              Reaction  N_observed_hw    PRRR  \\\n",
      "0   D07704   Citalopram        Rhabdomyolysis              7  79.281   \n",
      "1   D08410  Pravastatin         Hyponatraemia             19  47.598   \n",
      "3   D03257  Trastuzumab          Hypokalaemia              7  40.980   \n",
      "4   D00235     Atenolol  Condition aggravated              8  39.510   \n",
      "5   D00354  Lamotrigine            Aggression              4  34.204   \n",
      "\n",
      "                                         group_paths  \n",
      "0  [[Neuropsychiatric agent], [Metabolizing enzym...  \n",
      "1   [[Hypolipidemic agent], [Transporter substrate]]  \n",
      "3                                 [[Antineoplastic]]  \n",
      "4                           [[Cardiovascular agent]]  \n",
      "5  [[Metabolizing enzyme substrate], [Neuropsychi...  \n"
     ]
    }
   ],
   "source": [
    "dc_df = pd.read_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison_final_0.csv', sep='$', header=0, index_col=None)\n",
    "\n",
    "def find_paths(brite_dict, d_number):\n",
    "    paths = []\n",
    "\n",
    "    def traverse(node, current_path):\n",
    "        if 'name' in node and d_number in node['name']:\n",
    "            paths.append(current_path + [node['name']])\n",
    "        elif 'children' in node:\n",
    "            for child in node['children']:\n",
    "                traverse(child, current_path + [node['name']])\n",
    "\n",
    "    traverse(brite_dict, [])\n",
    "    return paths\n",
    "\n",
    "\n",
    "# capitalize the first letter in the column 'Drug' in dc_df\n",
    "dc_df['Drug'] = dc_df['Drug'].str.capitalize()\n",
    "# create a column 'group_paths' in dc_df\n",
    "dc_df['group_paths'] = ''\n",
    "\n",
    "\n",
    "# iterate through each row in dc_df\n",
    "for index, row in dc_df.iterrows():\n",
    "\n",
    "    drug_paths_brite = find_paths(brite, row['D_number'])\n",
    "    drug_paths_brite_class = find_paths(brite_class, row['D_number'])\n",
    "    drg = row['Drug']\n",
    "\n",
    "\n",
    "    if len(drug_paths_brite) > 0:\n",
    "        for sub_list in drug_paths_brite:\n",
    "            # remove the first element in the list\n",
    "            sub_list.pop(0)\n",
    "            # remove the last element in the list\n",
    "            sub_list.pop(-1)\n",
    "            last_element = sub_list[-1]\n",
    "            # if drg is in last_element, remove last element\n",
    "            if drg in last_element:\n",
    "                sub_list.pop(-1)\n",
    "\n",
    "\n",
    "    if len(drug_paths_brite_class) > 0:\n",
    "        for sub_list in drug_paths_brite_class:\n",
    "            # remove the first element in the list\n",
    "            sub_list.pop(0)\n",
    "            # remove the last element in the list\n",
    "            sub_list.pop(-1)\n",
    "            last_element = sub_list[-1]\n",
    "            # if drg is in last_element, remove last element\n",
    "            if drg in last_element:\n",
    "                sub_list.pop(-1)\n",
    "\n",
    "\n",
    "    # combine the two lists\n",
    "    drug_paths = drug_paths_brite + drug_paths_brite_class\n",
    "\n",
    "    for list in drug_paths:\n",
    "        while len(list) > 1:\n",
    "            # remove the second element in the list\n",
    "            list.pop(1)\n",
    "    \n",
    "    ind = 0\n",
    "    if True:    \n",
    "        for list in drug_paths:\n",
    "            # if list is the same as a previous list, remove it\n",
    "            while drug_paths.count(list) > 1:\n",
    "                drug_paths.pop(ind)\n",
    "            ind += 1\n",
    "\n",
    "    # set the value of the column 'group_paths' to the list drug_paths\n",
    "    dc_df.at[index, 'group_paths'] = drug_paths\n",
    "\n",
    "dc_df = dc_df[dc_df.astype(str)['group_paths'] != '[]']\n",
    "dc_df1 = dc_df.copy()\n",
    "\n",
    "print(dc_df.head())\n",
    "\n",
    "\n",
    "dc_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison_final_1.csv', sep='$', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "dc_df = dc_df1.copy()\n",
    "\n",
    "dc_df['group_paths'] = dc_df['group_paths'].astype(str)\n",
    "\n",
    "# drop rows with irrelevant reactions\n",
    "dc_df = dc_df[dc_df['Reaction'] != 'Condition aggravated']\n",
    "dc_df = dc_df[dc_df['Reaction'] != 'Drug abuse']\n",
    "dc_df = dc_df[dc_df['Reaction'] != 'Accidental overdose']\n",
    "dc_df = dc_df[dc_df['Reaction'] != 'Drug interaction']\n",
    "\n",
    "dc_df['drug_count'] = dc_df.groupby(['Drug'])['Drug'].transform('count')\n",
    "dc_df['reaction_count'] = dc_df.groupby(['Reaction'])['Reaction'].transform('count')\n",
    "dc_df['group_paths_count'] = dc_df.groupby(['group_paths'])['group_paths'].transform('count')\n",
    "\n",
    "\n",
    "# drop rows where the column 'reaction_count' is less than 5\n",
    "# dc_df = dc_df[dc_df['reaction_count'] >= 5]\n",
    "\n",
    "# drop rows where the column 'group_paths_count' is less than 5\n",
    "#dc_df = dc_df[dc_df['group_paths_count'] >= 5]\n",
    "\n",
    "# drop rows where the column 'drug_count' is less than 5\n",
    "# dc_df = dc_df[dc_df['drug_count'] >= 5]\n",
    "\n",
    "# drop duplicate rows\n",
    "dc_df['group_paths'] = dc_df['group_paths'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# drop rows with PRRR < 200\n",
    "dc_df = dc_df[dc_df['PRRR'] >= 20]\n",
    "# drop rows with N_observed_hw < 5\n",
    "dc_df = dc_df[dc_df['N_observed_hw'] >= 5]\n",
    "\n",
    "# order by N_observed_hw descending\n",
    "dc_df = dc_df.sort_values(by=['N_observed_hw'], ascending=False)\n",
    "\n",
    "\n",
    "print(len(dc_df))\n",
    "\n",
    "dc_df.to_csv('/Users/loaner/Documents/GitHub/Symbolic-Methods-FAERS-Project/text_files/drug_comparison_final_2.csv', sep='$', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "link": {
          "source": [
           0,
           1,
           3,
           1,
           4,
           5,
           7,
           5,
           7,
           8,
           10,
           11,
           12,
           13,
           7,
           13,
           12,
           15,
           7,
           15,
           16,
           15,
           3,
           15,
           12,
           17,
           7,
           17,
           16,
           17,
           19,
           17,
           10,
           20,
           21,
           22,
           12,
           22,
           24,
           22,
           7,
           22,
           12,
           25,
           7,
           25,
           27,
           28,
           7,
           28,
           16,
           28,
           7,
           30,
           12,
           30,
           10,
           31,
           33,
           34,
           36,
           34,
           12,
           37,
           12,
           38,
           7,
           38,
           40,
           41,
           21,
           42
          ],
          "target": [
           1,
           2,
           1,
           2,
           5,
           6,
           5,
           6,
           8,
           9,
           11,
           9,
           13,
           14,
           13,
           14,
           15,
           14,
           15,
           14,
           15,
           14,
           15,
           14,
           17,
           18,
           17,
           18,
           17,
           18,
           17,
           18,
           20,
           9,
           22,
           23,
           22,
           23,
           22,
           23,
           22,
           23,
           25,
           26,
           25,
           26,
           28,
           29,
           28,
           29,
           28,
           29,
           30,
           23,
           30,
           23,
           31,
           32,
           34,
           35,
           34,
           35,
           37,
           35,
           38,
           39,
           38,
           39,
           41,
           29,
           42,
           43
          ],
          "value": [
           19,
           19,
           19,
           19,
           16,
           16,
           16,
           16,
           8,
           8,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           7,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           6,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5,
           5
          ]
         },
         "node": {
          "label": [
           "Hypolipidemic agent, 19",
           "Pravastatin, 38",
           "Hyponatraemia, 38",
           "Transporter substrate, 26",
           "Blood modifier agent, 16",
           "Warfarin, 32",
           "Pruritus, 32",
           "Metabolizing enzyme substrate, 74",
           "Docetaxel, 8",
           "Hypokalaemia, 22",
           "Antineoplastic, 20",
           "Pertuzumab, 7",
           "Neuropsychiatric agent, 49",
           "Alprazolam, 14",
           "Rhabdomyolysis, 42",
           "Citalopram, 28",
           "Metabolizing enzyme inhibitor, 20",
           "Fluoxetine, 28",
           "Abdominal pain, 28",
           "Transporter inhibitor, 7",
           "Trastuzumab, 7",
           "Cardiovascular agent, 11",
           "Mirtazapine, 24",
           "Pneumonia aspiration, 36",
           "Gastrointestinal agent, 6",
           "Sertraline, 12",
           "Hallucination; visual, 12",
           "Antiparasitic, 6",
           "Metronidazole, 18",
           "Rash, 23",
           "Diazepam, 12",
           "Gemcitabine, 6",
           "Interstitial lung disease, 6",
           "Metabolizing enzyme inducer, 5",
           "Insulin lispro, 10",
           "Syncope, 15",
           "Antidiabetic agent, 5",
           "Gabapentin, 5",
           "Aripiprazole, 10",
           "Seizure, 10",
           "Antibacterial, 5",
           "Ceftriaxone, 5",
           "Valsartan, 5",
           "Neutropenia, 5"
          ],
          "line": {
           "color": "black",
           "width": 0.5
          },
          "pad": 15,
          "thickness": 20
         },
         "type": "sankey"
        }
       ],
       "layout": {
        "font": {
         "family": "Arial",
         "size": 16
        },
        "height": 1200,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 24
         },
         "text": "Sankey Diagram of Drug Groups, Drugs, and Reactions \n PRRR > 20, N>5"
        },
        "width": 1600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Extract the drug IDs, drug names, reactions, group_paths, and number_observed values\n",
    "drug_ids = dc_df[\"D_number\"].tolist()\n",
    "drug_names = dc_df[\"Drug\"].tolist()\n",
    "reactions = dc_df[\"Reaction\"].tolist()\n",
    "group_paths = dc_df[\"group_paths\"].tolist()\n",
    "number_observed = dc_df[\"N_observed_hw\"].tolist()\n",
    "\n",
    "# Process the group_paths and reactions for the Sankey diagram\n",
    "labels = []\n",
    "source = []\n",
    "target = []\n",
    "value = []\n",
    "\n",
    "# Iterate through the drug IDs, drug names, reactions, and number_observed values\n",
    "for drug_id, drug_name, reaction, group_path, observed in zip(drug_ids, drug_names, reactions, group_paths, number_observed):\n",
    "    # Convert string representation of list to an actual list\n",
    "    # group_path = eval(group_path)\n",
    "\n",
    "    for path in group_path:\n",
    "        # Create a new list for each drug group, drug, and reaction\n",
    "        node_path = path + [drug_name, reaction]\n",
    "\n",
    "        # Iterate through the node_path\n",
    "        for i in range(len(node_path) - 1):\n",
    "            # Add the nodes to the labels list\n",
    "            if node_path[i] not in labels:\n",
    "                labels.append(node_path[i])\n",
    "            # Add the nodes to the labels list\n",
    "            if node_path[i + 1] not in labels:\n",
    "                labels.append(node_path[i + 1])\n",
    "\n",
    "            source_idx = labels.index(node_path[i])\n",
    "            target_idx = labels.index(node_path[i + 1])\n",
    "\n",
    "            source.append(source_idx)\n",
    "            target.append(target_idx)\n",
    "            value.append(observed)\n",
    "\n",
    "# Update the labels with node sizes\n",
    "for idx, label in enumerate(labels):\n",
    "    mysum = 0\n",
    "    for i, source_idx in enumerate(source):\n",
    "        if source_idx == idx:\n",
    "            mysum += value[i]\n",
    "    node_value = mysum\n",
    "    \n",
    "    if node_value == 0:\n",
    "        # set the node value to the sum of values for the first row with that label as the reaction\n",
    "        node_value = sum(value[j] for j, target_idx in enumerate(target) if labels[target_idx] == label)\n",
    "\n",
    "    if node_value > 0:\n",
    "        node_value = int(node_value)\n",
    "\n",
    "    labels[idx] = f\"{label}, {node_value}\"\n",
    "    labels[idx] = f\"{label}, {node_value}\"\n",
    "\n",
    "\n",
    "# Create the Sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(pad=15, thickness=20, line=dict(color=\"black\", width=0.5), label=labels),\n",
    "    link=dict(source=source, target=target, value=value)\n",
    ")])\n",
    "# bold font for the labels\n",
    "fig.update_layout(title_text=\"Sankey Diagram of Drug Groups, Drugs, and Reactions \\n PRRR > 20, N>5\", width=1600, height=1200, font_size=16, font_family=\"Arial\", title_font_size=24)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25bed791a1aed4bb13420da74a485fcfdcafbc9ecdc61a40322d51322f2b5a38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
